// examples/proteins_lookup.rs
//
// Demo: protein-like vector DB with λ-band search using arrowspace-rs.
//
// Model:
// - Let N items (“proteins”), each with F features.
// - Build ArrowSpace with rows = features (F), cols = items (N).
// - Build a KNN Laplacian on item coordinates and compute λ per feature-row.
// - Query:
//   1) A target vector q in R^F.
//   2) A λ target and tolerance Δ. Only features whose λ ∈ [λ0-Δ, λ0+Δ] contribute to cosine.
//   3) Rank items by that restricted cosine and return top-k.
//
// This emulates a “range-by-score” on λ while doing vector search.
//
// Dependencies: arrowspace crate in this repo.
// Run: cargo run --example proteins_lookup

use ordered_float::OrderedFloat;
use arrowspace::builder::ArrowSpaceBuilder;
use std::collections::BTreeMap;

#[path = "./common/lib.rs"]
mod common;

// ------------ Data block: 64 items x 24 dims ------------
// Each line: id; f0,f1,...,f23
// These are small, normalized-ish floats to mimic compact “feature” descriptors
// derived from protein signals (e.g., temporal+spatial MD descriptors).
const VECTORS_DATA: &str = r#"
P0001; 0.82,0.11,0.43,0.28,0.64,0.32,0.55,0.48,0.19,0.73,0.07,0.36,0.58,0.23,0.44,0.31,0.52,0.16,0.61,0.40,0.27,0.49,0.35,0.29
P0002; 0.79,0.12,0.45,0.29,0.61,0.33,0.54,0.47,0.21,0.70,0.08,0.37,0.56,0.22,0.46,0.30,0.51,0.18,0.60,0.39,0.26,0.48,0.36,0.30
P0003; 0.78,0.13,0.46,0.27,0.62,0.34,0.53,0.46,0.22,0.69,0.09,0.35,0.55,0.24,0.45,0.29,0.50,0.17,0.59,0.38,0.28,0.47,0.34,0.31
P0004; 0.81,0.10,0.44,0.26,0.63,0.31,0.56,0.45,0.20,0.71,0.06,0.34,0.57,0.25,0.47,0.33,0.53,0.15,0.62,0.41,0.25,0.50,0.37,0.27
P0005; 0.80,0.12,0.42,0.25,0.60,0.35,0.52,0.49,0.23,0.68,0.10,0.38,0.54,0.21,0.43,0.28,0.49,0.19,0.58,0.37,0.29,0.46,0.33,0.32
P0006; 0.77,0.14,0.41,0.24,0.59,0.36,0.51,0.50,0.24,0.67,0.11,0.39,0.53,0.20,0.42,0.27,0.48,0.20,0.57,0.36,0.30,0.45,0.32,0.33
P0007; 0.83,0.09,0.47,0.30,0.65,0.33,0.57,0.44,0.18,0.72,0.05,0.33,0.59,0.26,0.48,0.34,0.54,0.14,0.63,0.42,0.24,0.51,0.38,0.26
P0008; 0.76,0.15,0.40,0.23,0.58,0.37,0.50,0.51,0.25,0.66,0.12,0.40,0.52,0.19,0.41,0.26,0.47,0.21,0.56,0.35,0.31,0.44,0.31,0.34
P0009; 0.75,0.16,0.39,0.22,0.57,0.38,0.49,0.52,0.26,0.65,0.13,0.41,0.51,0.18,0.40,0.25,0.46,0.22,0.55,0.34,0.32,0.43,0.30,0.35
P0010; 0.84,0.08,0.48,0.31,0.66,0.32,0.58,0.43,0.17,0.74,0.04,0.32,0.60,0.27,0.49,0.35,0.55,0.13,0.64,0.43,0.23,0.52,0.39,0.25
P0011; 0.72,0.18,0.37,0.21,0.55,0.39,0.47,0.54,0.27,0.63,0.15,0.42,0.49,0.17,0.39,0.24,0.45,0.23,0.54,0.33,0.33,0.42,0.29,0.36
P00112; 0.73,0.17,0.38,0.20,0.56,0.40,0.48,0.53,0.28,0.64,0.14,0.43,0.50,0.16,0.38,0.23,0.44,0.24,0.53,0.32,0.34,0.41,0.28,0.37
P0013; 0.71,0.19,0.36,0.19,0.54,0.41,0.46,0.55,0.29,0.62,0.16,0.44,0.48,0.15,0.37,0.22,0.43,0.25,0.52,0.31,0.35,0.40,0.27,0.38
P0014; 0.85,0.07,0.49,0.32,0.67,0.31,0.59,0.42,0.16,0.75,0.03,0.31,0.61,0.28,0.50,0.36,0.56,0.12,0.65,0.44,0.22,0.53,0.40,0.24
P0015; 0.70,0.20,0.35,0.18,0.53,0.42,0.45,0.56,0.30,0.61,0.17,0.45,0.47,0.14,0.36,0.21,0.42,0.26,0.51,0.30,0.36,0.39,0.26,0.39
P0016; 0.69,0.21,0.34,0.17,0.52,0.43,0.44,0.57,0.31,0.60,0.18,0.46,0.46,0.13,0.35,0.20,0.41,0.27,0.50,0.29,0.37,0.38,0.25,0.40
P0017; 0.86,0.06,0.50,0.33,0.68,0.30,0.60,0.41,0.15,0.76,0.02,0.30,0.62,0.29,0.51,0.37,0.57,0.11,0.66,0.45,0.21,0.54,0.41,0.23
P0018; 0.68,0.22,0.33,0.16,0.51,0.44,0.43,0.58,0.32,0.59,0.19,0.47,0.45,0.12,0.34,0.19,0.40,0.28,0.49,0.28,0.38,0.37,0.24,0.41
P0019; 0.67,0.23,0.32,0.15,0.50,0.45,0.42,0.59,0.33,0.58,0.20,0.48,0.44,0.11,0.33,0.18,0.39,0.29,0.48,0.27,0.39,0.36,0.23,0.42
P0020; 0.87,0.05,0.51,0.34,0.69,0.29,0.61,0.40,0.14,0.77,0.01,0.29,0.63,0.30,0.52,0.38,0.58,0.10,0.67,0.46,0.20,0.55,0.42,0.22
P0021; 0.66,0.24,0.31,0.14,0.49,0.46,0.41,0.60,0.34,0.57,0.21,0.49,0.43,0.10,0.32,0.17,0.38,0.30,0.47,0.26,0.40,0.35,0.22,0.43
P0022; 0.65,0.25,0.30,0.13,0.48,0.47,0.40,0.61,0.35,0.56,0.22,0.50,0.42,0.09,0.31,0.16,0.37,0.31,0.46,0.25,0.41,0.34,0.21,0.44
P0023; 0.64,0.26,0.29,0.12,0.47,0.48,0.39,0.62,0.36,0.55,0.23,0.51,0.41,0.08,0.30,0.15,0.36,0.32,0.45,0.24,0.42,0.33,0.20,0.45
P0024; 0.88,0.04,0.52,0.35,0.70,0.28,0.62,0.39,0.13,0.78,0.00,0.28,0.64,0.31,0.53,0.39,0.59,0.09,0.68,0.47,0.19,0.56,0.43,0.21
P0025; 0.63,0.27,0.28,0.11,0.46,0.49,0.38,0.63,0.37,0.54,0.24,0.52,0.40,0.07,0.29,0.14,0.35,0.33,0.44,0.23,0.43,0.32,0.19,0.46
P0026; 0.62,0.28,0.27,0.10,0.45,0.50,0.37,0.64,0.38,0.53,0.25,0.53,0.39,0.06,0.28,0.13,0.34,0.34,0.43,0.22,0.44,0.31,0.18,0.47
P0027; 0.61,0.29,0.26,0.09,0.44,0.51,0.36,0.65,0.39,0.52,0.26,0.54,0.38,0.05,0.27,0.12,0.33,0.35,0.42,0.21,0.45,0.30,0.17,0.48
P0028; 0.60,0.30,0.25,0.08,0.43,0.52,0.35,0.66,0.40,0.51,0.27,0.55,0.37,0.04,0.26,0.11,0.32,0.36,0.41,0.20,0.46,0.29,0.16,0.49
P0029; 0.59,0.31,0.24,0.07,0.42,0.53,0.34,0.67,0.41,0.50,0.28,0.56,0.36,0.03,0.25,0.10,0.31,0.37,0.40,0.19,0.47,0.28,0.15,0.50
P0030; 0.58,0.32,0.23,0.06,0.41,0.54,0.33,0.68,0.42,0.49,0.29,0.57,0.35,0.02,0.24,0.09,0.30,0.38,0.39,0.18,0.48,0.27,0.14,0.51
P0031; 0.90,0.06,0.44,0.36,0.72,0.33,0.55,0.41,0.20,0.79,0.05,0.35,0.60,0.26,0.46,0.31,0.54,0.16,0.62,0.42,0.27,0.49,0.35,0.29
P0032; 0.57,0.33,0.22,0.05,0.40,0.55,0.32,0.69,0.43,0.48,0.30,0.58,0.34,0.01,0.23,0.08,0.29,0.39,0.38,0.17,0.49,0.26,0.13,0.52
P0033; 0.56,0.34,0.21,0.04,0.39,0.56,0.31,0.70,0.44,0.47,0.31,0.59,0.33,0.00,0.22,0.07,0.28,0.40,0.37,0.16,0.50,0.25,0.12,0.53
P0034; 0.55,0.35,0.20,0.03,0.38,0.57,0.30,0.71,0.45,0.46,0.32,0.60,0.32,0.02,0.21,0.06,0.27,0.41,0.36,0.15,0.51,0.24,0.11,0.54
P0035; 0.54,0.36,0.19,0.02,0.37,0.58,0.29,0.72,0.46,0.45,0.33,0.61,0.31,0.03,0.20,0.05,0.26,0.42,0.35,0.14,0.52,0.23,0.10,0.55
P0036; 0.53,0.37,0.18,0.01,0.36,0.59,0.28,0.73,0.47,0.44,0.34,0.62,0.30,0.04,0.19,0.04,0.25,0.43,0.34,0.13,0.53,0.22,0.09,0.56
P0037; 0.91,0.07,0.45,0.37,0.73,0.34,0.56,0.40,0.21,0.80,0.06,0.36,0.61,0.27,0.47,0.32,0.55,0.17,0.63,0.41,0.28,0.50,0.36,0.28
P0038; 0.52,0.38,0.17,0.00,0.35,0.60,0.27,0.74,0.48,0.43,0.35,0.63,0.29,0.05,0.18,0.03,0.24,0.44,0.33,0.12,0.54,0.21,0.08,0.57
P0039; 0.51,0.39,0.16,0.02,0.34,0.61,0.26,0.75,0.49,0.42,0.36,0.64,0.28,0.06,0.17,0.02,0.23,0.45,0.32,0.11,0.55,0.20,0.07,0.58
P0040; 0.50,0.40,0.15,0.03,0.33,0.62,0.25,0.76,0.50,0.41,0.37,0.65,0.27,0.07,0.16,0.01,0.22,0.46,0.31,0.10,0.56,0.19,0.06,0.59
P0041; 0.49,0.41,0.14,0.04,0.32,0.63,0.24,0.77,0.51,0.40,0.38,0.66,0.26,0.08,0.15,0.00,0.21,0.47,0.30,0.09,0.57,0.18,0.05,0.60
P0042; 0.48,0.42,0.13,0.05,0.31,0.64,0.23,0.78,0.52,0.39,0.39,0.67,0.25,0.09,0.14,0.02,0.20,0.48,0.29,0.08,0.58,0.17,0.04,0.61
P0043; 0.47,0.43,0.12,0.06,0.30,0.65,0.22,0.79,0.53,0.38,0.40,0.68,0.24,0.10,0.13,0.03,0.19,0.49,0.28,0.07,0.59,0.16,0.03,0.62
P0044; 0.46,0.44,0.11,0.07,0.29,0.66,0.21,0.80,0.54,0.37,0.41,0.69,0.23,0.11,0.12,0.04,0.18,0.50,0.27,0.06,0.60,0.15,0.02,0.63
P0045; 0.45,0.45,0.10,0.08,0.28,0.67,0.20,0.81,0.55,0.36,0.42,0.70,0.22,0.12,0.11,0.05,0.17,0.51,0.26,0.05,0.61,0.14,0.01,0.64
P0046; 0.44,0.46,0.09,0.09,0.27,0.68,0.19,0.82,0.56,0.35,0.43,0.71,0.21,0.13,0.10,0.06,0.16,0.52,0.25,0.04,0.62,0.13,0.00,0.65
P0047; 0.43,0.47,0.08,0.10,0.26,0.69,0.18,0.83,0.57,0.34,0.44,0.72,0.20,0.14,0.09,0.07,0.15,0.53,0.24,0.03,0.63,0.12,0.01,0.66
P0048; 0.42,0.48,0.07,0.11,0.25,0.70,0.17,0.84,0.58,0.33,0.45,0.73,0.19,0.15,0.08,0.08,0.14,0.54,0.23,0.02,0.64,0.11,0.02,0.67
P0049; 0.41,0.49,0.06,0.12,0.24,0.71,0.16,0.85,0.59,0.32,0.46,0.74,0.18,0.16,0.07,0.09,0.13,0.55,0.22,0.01,0.65,0.10,0.03,0.68
P0050; 0.40,0.50,0.05,0.13,0.23,0.72,0.15,0.86,0.60,0.31,0.47,0.75,0.17,0.17,0.06,0.10,0.12,0.56,0.21,0.00,0.66,0.09,0.04,0.69
P0051; 0.89,0.09,0.46,0.38,0.71,0.35,0.57,0.39,0.22,0.77,0.07,0.37,0.62,0.25,0.48,0.30,0.56,0.18,0.64,0.40,0.29,0.51,0.37,0.27
P0052; 0.39,0.51,0.04,0.14,0.22,0.73,0.14,0.87,0.61,0.30,0.48,0.76,0.16,0.18,0.05,0.11,0.11,0.57,0.20,0.02,0.67,0.08,0.05,0.70
P0053; 0.38,0.52,0.03,0.15,0.21,0.74,0.13,0.88,0.62,0.29,0.49,0.77,0.15,0.19,0.04,0.12,0.10,0.58,0.19,0.03,0.68,0.07,0.06,0.71
P0054; 0.37,0.53,0.02,0.16,0.20,0.75,0.12,0.89,0.63,0.28,0.50,0.78,0.14,0.20,0.03,0.13,0.09,0.59,0.18,0.04,0.69,0.06,0.07,0.72
P0055; 0.36,0.54,0.01,0.17,0.19,0.76,0.11,0.90,0.64,0.27,0.51,0.79,0.13,0.21,0.02,0.14,0.08,0.60,0.17,0.05,0.70,0.05,0.08,0.73
P0056; 0.35,0.55,0.00,0.18,0.18,0.77,0.10,0.91,0.65,0.26,0.52,0.80,0.12,0.22,0.01,0.15,0.07,0.61,0.16,0.06,0.71,0.04,0.09,0.74
P0057; 0.34,0.56,0.02,0.19,0.17,0.78,0.09,0.92,0.66,0.25,0.53,0.81,0.11,0.23,0.00,0.16,0.06,0.62,0.15,0.07,0.72,0.03,0.10,0.75
P0058; 0.33,0.57,0.03,0.20,0.16,0.79,0.08,0.93,0.67,0.24,0.54,0.82,0.10,0.24,0.01,0.17,0.05,0.63,0.14,0.08,0.73,0.02,0.11,0.76
P0059; 0.32,0.58,0.04,0.21,0.15,0.80,0.07,0.94,0.68,0.23,0.55,0.83,0.09,0.25,0.02,0.18,0.04,0.64,0.13,0.09,0.74,0.01,0.12,0.77
P0060; 0.31,0.59,0.05,0.22,0.14,0.81,0.06,0.95,0.69,0.22,0.56,0.84,0.08,0.26,0.03,0.19,0.03,0.65,0.12,0.10,0.75,0.00,0.13,0.78
P0061; 0.93,0.06,0.52,0.29,0.74,0.27,0.61,0.38,0.15,0.81,0.03,0.28,0.64,0.31,0.53,0.39,0.58,0.12,0.67,0.46,0.20,0.56,0.43,0.21
P0062; 0.30,0.60,0.06,0.23,0.13,0.82,0.05,0.96,0.70,0.21,0.57,0.85,0.07,0.27,0.04,0.20,0.02,0.66,0.11,0.11,0.76,0.01,0.14,0.79
P0063; 0.29,0.61,0.07,0.24,0.12,0.83,0.04,0.97,0.71,0.20,0.58,0.86,0.06,0.28,0.05,0.21,0.01,0.67,0.10,0.12,0.77,0.02,0.15,0.80
P0064; 0.28,0.62,0.08,0.25,0.11,0.84,0.03,0.98,0.72,0.19,0.59,0.87,0.05,0.29,0.06,0.22,0.00,0.68,0.09,0.13,0.78,0.03,0.16,0.81
"#;

fn main() {
    // 1) Load items
    let (ids, items_nxf) = common::parse_vectors_string(VECTORS_DATA);

    // Configure lambda-graph directly from the data matrix (rows = features over items)
    // Choose parameters analogous to the prior KNN setup:
    //   eps: λ proximity threshold
    //   k: optional cap on neighbors per item
    //   p: kernel exponent
    //   sigma_override: None => σ defaults to eps
    let eps = 0.05;        // Larger epsilon for more connected graph
    let k = 12usize;       // More neighbors for stability (trade-off with items)
    let p = 2.0;           // Linear kernel less sensitive to outliers  
    let sigma_override = Some(eps * 0.5);  // Explicit sigma control

    let (aspace, _) = ArrowSpaceBuilder::new()
        .with_lambda_graph(eps, k, p, sigma_override)
        .build(items_nxf.clone());

    // 2) Prepare a query vector near P0004
    let q_index = 3;
    let query = items_nxf[q_index].clone();

    println!("Querying the dataset with query: {query:?}");

    // 3) Per-item lambda scores
    let lambdas = aspace.lambdas().to_vec();

    // 4) Build ZSET
    let mut zset = ZSetIndex::new();
    for (i, id) in ids.iter().enumerate() {
        zset.zadd(lambdas[i], i, id.clone(), items_nxf[i].clone());
    }

    // 5) Query λ for the query vector 
    // define a band of querying arond the query vector
    
    let lambda_q = lambdas[q_index];
    let band = std_deviation(&lambdas).unwrap() as f64 / 2.0_f64.powf(p);
    let lo = lambda_q - band;
    let hi = lambda_q + band;

    println!("{:?}", std_deviation(&lambdas));

    let hits = zset.range_byscore(lo, hi, 0, Some(5));
    println!(
        "Query λ={:.6}, range [{:.6}, {:.6}] => {} hits",
        lambda_q,
        lo,
        hi,
        hits.len()
    );
    for (rank, (idx, score, id, _vecv)) in hits.iter().enumerate() {
        println!("{:2}. λ={:.6} {} (idx={})", rank + 1, score, id, idx);
    }
}

fn mean(data: &Vec<f64>) -> Option<f32> {
    let sum = data.iter().sum::<f64>() as f32;
    let count = data.len();

    match count {
        positive if positive > 0 => Some(sum / count as f32),
        _ => None,
    }
}

fn std_deviation(data: &Vec<f64>) -> Option<f32> {
    match (mean(data), data.len()) {
        (Some(data_mean), count) if count > 0 => {
            let variance = data
                .iter()
                .map(|value| {
                    let diff = data_mean - (*value as f32);

                    diff * diff
                })
                .sum::<f32>()
                / count as f32;

            Some(variance.sqrt())
        }
        _ => None,
    }
}

#[derive(Default)]
struct ZSetIndex {
    // Now map from OrderedFloat score -> members
    map: BTreeMap<OrderedFloat<f64>, Vec<(usize, String, Vec<f64>)>>,
}

impl ZSetIndex {
    fn new() -> Self {
        Self {
            map: BTreeMap::new(),
        }
    }

    fn zadd(&mut self, score: f64, idx: usize, id: String, item: Vec<f64>) {
        // Use OrderedFloat for key (allows NaN but results in panic on comparison if NaN).
        // If you want to forbid NaN explicitly, stick with NotNan instead.
        let key = OrderedFloat(score);
        let bucket = self.map.entry(key).or_default();
        bucket.push((idx, id, item));

        // Sort ties within same score by lexicographic ID
        bucket.sort_by(|a, b| a.1.cmp(&b.1));
    }

    fn range_byscore(
        &self,
        min: f64,
        max: f64,
        offset: usize,
        count: Option<usize>,
    ) -> Vec<(usize, f64, String, Vec<f64>)> {
        let lo = OrderedFloat(min);
        let hi = OrderedFloat(max);
        let mut out = Vec::new();

        for (k, bucket) in self.map.range(lo..=hi) {
            for (idx, id, vecv) in bucket {
                out.push((*idx, k.0, id.clone(), vecv.clone()));
            }
        }
        if offset >= out.len() {
            return Vec::new();
        }
        let end = match count {
            Some(c) => (offset + c).min(out.len()),
            None => out.len(),
        };
        out[offset..end].to_vec()
    }
}
